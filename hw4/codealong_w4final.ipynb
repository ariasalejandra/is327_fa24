{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data manually\n",
    "\n",
    "* Really manually, i.e., with separate files\n",
    "* In code with one dataset (e.g., how homework has gone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car</td>\n",
       "      <td>1.27</td>\n",
       "      <td>91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>231.38</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.47</td>\n",
       "      <td>207.92</td>\n",
       "      <td>241.74</td>\n",
       "      <td>244.48</td>\n",
       "      <td>...</td>\n",
       "      <td>26.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.29</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>56</td>\n",
       "      <td>3806.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.36</td>\n",
       "      <td>241</td>\n",
       "      <td>1.56</td>\n",
       "      <td>216.15</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.51</td>\n",
       "      <td>187.85</td>\n",
       "      <td>229.39</td>\n",
       "      <td>231.20</td>\n",
       "      <td>...</td>\n",
       "      <td>22.29</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.42</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1746</td>\n",
       "      <td>1450.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.12</td>\n",
       "      <td>266</td>\n",
       "      <td>1.47</td>\n",
       "      <td>232.18</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.21</td>\n",
       "      <td>206.54</td>\n",
       "      <td>244.22</td>\n",
       "      <td>245.79</td>\n",
       "      <td>...</td>\n",
       "      <td>15.59</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>566</td>\n",
       "      <td>1094.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.42</td>\n",
       "      <td>399</td>\n",
       "      <td>1.28</td>\n",
       "      <td>230.40</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.73</td>\n",
       "      <td>204.60</td>\n",
       "      <td>243.27</td>\n",
       "      <td>243.32</td>\n",
       "      <td>...</td>\n",
       "      <td>13.51</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.44</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1178</td>\n",
       "      <td>1125.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.15</td>\n",
       "      <td>944</td>\n",
       "      <td>1.73</td>\n",
       "      <td>193.18</td>\n",
       "      <td>2.28</td>\n",
       "      <td>4.10</td>\n",
       "      <td>165.98</td>\n",
       "      <td>205.55</td>\n",
       "      <td>208.00</td>\n",
       "      <td>...</td>\n",
       "      <td>15.65</td>\n",
       "      <td>50.08</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>6232</td>\n",
       "      <td>1146.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>car</td>\n",
       "      <td>1.43</td>\n",
       "      <td>39</td>\n",
       "      <td>1.41</td>\n",
       "      <td>234.03</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.60</td>\n",
       "      <td>206.36</td>\n",
       "      <td>246.05</td>\n",
       "      <td>249.69</td>\n",
       "      <td>...</td>\n",
       "      <td>55.92</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>66</td>\n",
       "      <td>2469.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>soil</td>\n",
       "      <td>1.92</td>\n",
       "      <td>141</td>\n",
       "      <td>1.24</td>\n",
       "      <td>215.19</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>212.28</td>\n",
       "      <td>216.28</td>\n",
       "      <td>217.00</td>\n",
       "      <td>...</td>\n",
       "      <td>18.91</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.06</td>\n",
       "      <td>990</td>\n",
       "      <td>824.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>grass</td>\n",
       "      <td>2.97</td>\n",
       "      <td>252</td>\n",
       "      <td>1.73</td>\n",
       "      <td>164.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.09</td>\n",
       "      <td>184.15</td>\n",
       "      <td>152.03</td>\n",
       "      <td>156.22</td>\n",
       "      <td>...</td>\n",
       "      <td>33.52</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.71</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.06</td>\n",
       "      <td>948</td>\n",
       "      <td>821.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>grass</td>\n",
       "      <td>1.57</td>\n",
       "      <td>216</td>\n",
       "      <td>1.27</td>\n",
       "      <td>164.84</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.97</td>\n",
       "      <td>192.55</td>\n",
       "      <td>148.34</td>\n",
       "      <td>153.62</td>\n",
       "      <td>...</td>\n",
       "      <td>24.49</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.09</td>\n",
       "      <td>254</td>\n",
       "      <td>1580.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.12</td>\n",
       "      <td>836</td>\n",
       "      <td>0.88</td>\n",
       "      <td>232.84</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.52</td>\n",
       "      <td>202.39</td>\n",
       "      <td>247.24</td>\n",
       "      <td>248.89</td>\n",
       "      <td>...</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7.16</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>3020</td>\n",
       "      <td>1611.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         class  BrdIndx  Area  Round  Bright  Compact  ShpIndx  Mean_G  \\\n",
       "0         car      1.27    91   0.97  231.38     1.39     1.47  207.92   \n",
       "1    concrete      2.36   241   1.56  216.15     2.46     2.51  187.85   \n",
       "2    concrete      2.12   266   1.47  232.18     2.07     2.21  206.54   \n",
       "3    concrete      2.42   399   1.28  230.40     2.49     2.73  204.60   \n",
       "4    concrete      2.15   944   1.73  193.18     2.28     4.10  165.98   \n",
       "..         ...      ...   ...    ...     ...      ...      ...     ...   \n",
       "163       car      1.43    39   1.41  234.03     1.54     1.60  206.36   \n",
       "164      soil      1.92   141   1.24  215.19     2.02     2.02  212.28   \n",
       "165     grass      2.97   252   1.73  164.13     3.20     3.09  184.15   \n",
       "166     grass      1.57   216   1.27  164.84     1.71     1.97  192.55   \n",
       "167  concrete      2.12   836   0.88  232.84     1.78     2.52  202.39   \n",
       "\n",
       "     Mean_R  Mean_NIR  ...  SD_NIR_140  LW_140  GLCM1_140  Rect_140  \\\n",
       "0    241.74    244.48  ...       26.18    2.00       0.50      0.85   \n",
       "1    229.39    231.20  ...       22.29    2.25       0.79      0.55   \n",
       "2    244.22    245.79  ...       15.59    2.19       0.76      0.74   \n",
       "3    243.27    243.32  ...       13.51    3.34       0.82      0.74   \n",
       "4    205.55    208.00  ...       15.65   50.08       0.85      0.49   \n",
       "..      ...       ...  ...         ...     ...        ...       ...   \n",
       "163  246.05    249.69  ...       55.92    1.73       0.65      0.81   \n",
       "164  216.28    217.00  ...       18.91    3.49       0.88      0.67   \n",
       "165  152.03    156.22  ...       33.52    2.02       0.86      0.71   \n",
       "166  148.34    153.62  ...       24.49    1.13       0.76      0.85   \n",
       "167  247.24    248.89  ...        7.84    1.52       0.76      0.24   \n",
       "\n",
       "     GLCM2_140  Dens_140  Assym_140  NDVI_140  BordLngth_140  GLCM3_140  \n",
       "0         6.29      1.67       0.70     -0.08             56    3806.36  \n",
       "1         8.42      1.38       0.81     -0.09           1746    1450.14  \n",
       "2         7.24      1.68       0.81     -0.07            566    1094.04  \n",
       "3         7.44      1.36       0.92     -0.09           1178    1125.38  \n",
       "4         8.15      0.23       1.00     -0.08           6232    1146.38  \n",
       "..         ...       ...        ...       ...            ...        ...  \n",
       "163       7.05      1.89       0.42     -0.10             66    2469.69  \n",
       "164       7.88      1.44       0.82      0.06            990     824.01  \n",
       "165       8.50      1.82       0.54      0.06            948     821.84  \n",
       "166       7.75      2.11       0.30      0.09            254    1580.72  \n",
       "167       7.16      0.74       0.49     -0.09           3020    1611.55  \n",
       "\n",
       "[168 rows x 148 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('Urban land cover/training.csv')\n",
    "train_df\n",
    "#class is our target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concrete</td>\n",
       "      <td>1.32</td>\n",
       "      <td>131</td>\n",
       "      <td>0.81</td>\n",
       "      <td>222.74</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.18</td>\n",
       "      <td>192.94</td>\n",
       "      <td>235.11</td>\n",
       "      <td>240.15</td>\n",
       "      <td>...</td>\n",
       "      <td>31.15</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1512</td>\n",
       "      <td>1287.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.59</td>\n",
       "      <td>864</td>\n",
       "      <td>0.94</td>\n",
       "      <td>47.56</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.87</td>\n",
       "      <td>36.82</td>\n",
       "      <td>48.78</td>\n",
       "      <td>57.09</td>\n",
       "      <td>...</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>2659.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.41</td>\n",
       "      <td>409</td>\n",
       "      <td>1.00</td>\n",
       "      <td>51.38</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.53</td>\n",
       "      <td>41.72</td>\n",
       "      <td>51.96</td>\n",
       "      <td>60.48</td>\n",
       "      <td>...</td>\n",
       "      <td>18.75</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.63</td>\n",
       "      <td>8.32</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1198</td>\n",
       "      <td>720.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>2.58</td>\n",
       "      <td>187</td>\n",
       "      <td>1.91</td>\n",
       "      <td>70.08</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.11</td>\n",
       "      <td>93.13</td>\n",
       "      <td>55.20</td>\n",
       "      <td>61.92</td>\n",
       "      <td>...</td>\n",
       "      <td>27.67</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.56</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>524</td>\n",
       "      <td>891.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asphalt</td>\n",
       "      <td>2.60</td>\n",
       "      <td>116</td>\n",
       "      <td>2.05</td>\n",
       "      <td>89.57</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.02</td>\n",
       "      <td>73.17</td>\n",
       "      <td>94.89</td>\n",
       "      <td>100.64</td>\n",
       "      <td>...</td>\n",
       "      <td>32.05</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.62</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>496</td>\n",
       "      <td>1194.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>building</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3146</td>\n",
       "      <td>0.90</td>\n",
       "      <td>244.97</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.39</td>\n",
       "      <td>229.86</td>\n",
       "      <td>252.47</td>\n",
       "      <td>252.58</td>\n",
       "      <td>...</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.84</td>\n",
       "      <td>6.85</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>784</td>\n",
       "      <td>1911.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>grass</td>\n",
       "      <td>2.51</td>\n",
       "      <td>428</td>\n",
       "      <td>1.55</td>\n",
       "      <td>166.02</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.61</td>\n",
       "      <td>210.11</td>\n",
       "      <td>135.89</td>\n",
       "      <td>152.04</td>\n",
       "      <td>...</td>\n",
       "      <td>18.91</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.70</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1020</td>\n",
       "      <td>801.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.45</td>\n",
       "      <td>659</td>\n",
       "      <td>1.38</td>\n",
       "      <td>219.30</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.53</td>\n",
       "      <td>189.64</td>\n",
       "      <td>233.14</td>\n",
       "      <td>235.12</td>\n",
       "      <td>...</td>\n",
       "      <td>14.67</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7.47</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>2596</td>\n",
       "      <td>1243.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>building</td>\n",
       "      <td>1.90</td>\n",
       "      <td>89</td>\n",
       "      <td>1.01</td>\n",
       "      <td>219.88</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.01</td>\n",
       "      <td>184.82</td>\n",
       "      <td>235.18</td>\n",
       "      <td>239.65</td>\n",
       "      <td>...</td>\n",
       "      <td>37.11</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>8.47</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>726</td>\n",
       "      <td>1470.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>building</td>\n",
       "      <td>2.48</td>\n",
       "      <td>155</td>\n",
       "      <td>1.68</td>\n",
       "      <td>225.15</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.69</td>\n",
       "      <td>192.61</td>\n",
       "      <td>239.95</td>\n",
       "      <td>242.88</td>\n",
       "      <td>...</td>\n",
       "      <td>10.50</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>296</td>\n",
       "      <td>1991.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         class  BrdIndx  Area  Round  Bright  Compact  ShpIndx  Mean_G  \\\n",
       "0    concrete      1.32   131   0.81  222.74     1.66     2.18  192.94   \n",
       "1      shadow      1.59   864   0.94   47.56     1.41     1.87   36.82   \n",
       "2      shadow      1.41   409   1.00   51.38     1.37     1.53   41.72   \n",
       "3        tree      2.58   187   1.91   70.08     3.41     3.11   93.13   \n",
       "4     asphalt      2.60   116   2.05   89.57     3.06     3.02   73.17   \n",
       "..         ...      ...   ...    ...     ...      ...      ...     ...   \n",
       "502  building      1.36  3146   0.90  244.97     1.44     1.39  229.86   \n",
       "503     grass      2.51   428   1.55  166.02     2.16     2.61  210.11   \n",
       "504  concrete      2.45   659   1.38  219.30     1.68     2.53  189.64   \n",
       "505  building      1.90    89   1.01  219.88     2.02     2.01  184.82   \n",
       "506  building      2.48   155   1.68  225.15     2.57     2.69  192.61   \n",
       "\n",
       "     Mean_R  Mean_NIR  ...  SD_NIR_140  LW_140  GLCM1_140  Rect_140  \\\n",
       "0    235.11    240.15  ...       31.15    5.04       0.80      0.58   \n",
       "1     48.78     57.09  ...       12.01    3.70       0.52      0.96   \n",
       "2     51.96     60.48  ...       18.75    3.09       0.90      0.63   \n",
       "3     55.20     61.92  ...       27.67    6.33       0.89      0.70   \n",
       "4     94.89    100.64  ...       32.05    1.01       0.83      0.75   \n",
       "..      ...       ...  ...         ...     ...        ...       ...   \n",
       "502  252.47    252.58  ...        7.58    1.51       0.63      0.84   \n",
       "503  135.89    152.04  ...       18.91    1.14       0.86      0.67   \n",
       "504  233.14    235.12  ...       14.67    2.21       0.74      0.78   \n",
       "505  235.18    239.65  ...       37.11    5.26       0.75      0.85   \n",
       "506  239.95    242.88  ...       10.50    3.92       0.71      0.85   \n",
       "\n",
       "     GLCM2_140  Dens_140  Assym_140  NDVI_140  BordLngth_140  GLCM3_140  \n",
       "0         8.56      0.82       0.98     -0.10           1512    1287.52  \n",
       "1         7.01      1.69       0.86     -0.14            196    2659.74  \n",
       "2         8.32      1.38       0.84      0.10           1198     720.38  \n",
       "3         8.56      1.10       0.96      0.20            524     891.36  \n",
       "4         8.62      2.08       0.08     -0.10            496    1194.76  \n",
       "..         ...       ...        ...       ...            ...        ...  \n",
       "502       6.85      1.96       0.47     -0.04            784    1911.96  \n",
       "503       7.70      1.80       0.50      0.22           1020     801.65  \n",
       "504       7.47      1.70       0.74     -0.09           2596    1243.03  \n",
       "505       8.47      1.30       0.94     -0.12            726    1470.63  \n",
       "506       6.74      1.52       0.89     -0.11            296    1991.25  \n",
       "\n",
       "[507 rows x 148 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('Urban land cover/testing.csv')\n",
    "test_df\n",
    "# class is our target label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our Decision Tree with 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test kappa: 0.5214255182731353\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree, metrics\n",
    "\n",
    "model = tree.DecisionTreeClassifier(min_samples_leaf=10)\n",
    "features = ['Area', 'Round', 'Bright', 'Compact']\n",
    "train_X = train_df[features]\n",
    "model.fit(train_X, train_df['class'])\n",
    "\n",
    "test_X = test_df[features]\n",
    "predictions = model.predict(test_X)\n",
    "kappa = metrics.cohen_kappa_score(test_df['class'], predictions)\n",
    "print('Test kappa:', kappa) # Note if we re-run it the results may differ slightly as is some randomness in CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing 2-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675 675\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the train_df and test_df datasets into a single combined_df. \n",
    "# Verify that the length of the combined dataframe matches the sum of the individual lengths of train_df and test_df.\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "print(len(combined_df), len(train_df) + len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5132893229087443"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the combined dataset, \n",
    "# Loop over 2 folds \n",
    "# Split the data into two halves (first_half and second_half)\n",
    "# In the first fold (fold_num == 0), use first half of the data for training and the second half for testing.\n",
    "# In the second fold (fold_num == 1), this is reversed: use the second half for training and the first half for testing.\n",
    "# Don't forget to evaluate on test at each round with kappa and compute the avg kappa at the end.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kf = KFold(n_splits=2, shuffle=True)\n",
    "kappas = []\n",
    "scores = []\n",
    "for fold_num, (train_index, test_index) in enumerate(kf.split(combined_df)):\n",
    "    if fold_num == 0:\n",
    "        train_df = combined_df.iloc[train_index]\n",
    "        test_df = combined_df.iloc[test_index]\n",
    "    else:\n",
    "        train_df = combined_df.iloc[test_index]\n",
    "        test_df = combined_df.iloc[train_index]\n",
    "    model = tree.DecisionTreeClassifier(min_samples_leaf=10)\n",
    "    model.fit(train_df[features], train_df['class'])\n",
    "    score = cross_val_score(model, train_df[features], train_df['class'], cv=kf)\n",
    "    scores.append(score)\n",
    "    predictions = model.predict(test_df[features])\n",
    "    kappa = metrics.cohen_kappa_score(test_df['class'], predictions)\n",
    "    kappas.append(kappa)\n",
    "\n",
    "np.mean(kappas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check class counts and accuracy for one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "building     122\n",
       "concrete     116\n",
       "grass        112\n",
       "tree         106\n",
       "shadow        61\n",
       "asphalt       59\n",
       "car           36\n",
       "soil          34\n",
       "pool          29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.508142919066196"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opened CSV file, and observed there is a space after the labels for some reason -.-\n",
    "test_y = test_df['class']\n",
    "building_predictions = predictions == 'building ' # boolean True for rows that model's predictions are the class 'building '\n",
    "building_predictions\n",
    "building_labels = test_y == 'building ' # boolean True for rows that ground-truth label are the class 'building '\n",
    "building_labels\n",
    "building_kappa = metrics.cohen_kappa_score(building_labels, building_predictions)\n",
    "building_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6007006680788659"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall kappa (across all classes)\n",
    "metrics.cohen_kappa_score(predictions, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New cross-validation fold\n",
      "[ 0  2  5  6  7  8  9 10 11 12]\n",
      "[ 1  3  4 18 27 50 51 57 62 83]\n",
      "607 68\n",
      "Kappa: 0.501138375917025\n",
      "New cross-validation fold\n",
      "[ 0  1  2  3  4  6  7  8  9 10]\n",
      "[ 5 14 26 32 42 45 54 58 80 84]\n",
      "607 68\n",
      "Kappa: 0.4534036674202462\n",
      "New cross-validation fold\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[ 24  36  38  55  60  77  88  93 123 125]\n",
      "607 68\n",
      "Kappa: 0.49938650306748467\n",
      "New cross-validation fold\n",
      "[ 0  1  2  3  4  5  6  7  9 10]\n",
      "[ 8 12 21 22 33 35 39 48 49 52]\n",
      "607 68\n",
      "Kappa: 0.4670846394984326\n",
      "New cross-validation fold\n",
      "[ 0  1  3  4  5  6  7  8  9 10]\n",
      "[  2  11  16  28  30  34  41  63  78 102]\n",
      "607 68\n",
      "Kappa: 0.604551201011378\n",
      "New cross-validation fold\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[19 20 23 25 29 44 68 79 82 98]\n",
      "608 67\n",
      "Kappa: 0.5197770108839925\n",
      "New cross-validation fold\n",
      "[ 0  1  2  3  4  5  7  8  9 10]\n",
      "[  6  17  37  40  61  65  70  71  99 109]\n",
      "608 67\n",
      "Kappa: 0.5882202304737516\n",
      "New cross-validation fold\n",
      "[ 0  1  2  3  4  5  6  8  9 10]\n",
      "[  7  15  43  56  59  73  89  97 100 103]\n",
      "608 67\n",
      "Kappa: 0.5751651254953765\n",
      "New cross-validation fold\n",
      "[ 1  2  3  4  5  6  7  8 11 12]\n",
      "[ 0  9 10 13 31 47 64 67 69 76]\n",
      "608 67\n",
      "Kappa: 0.591679915209327\n",
      "New cross-validation fold\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[ 46  53  72  75  90  92 101 106 108 117]\n",
      "608 67\n",
      "Kappa: 0.5502194681125743\n",
      "Kappa mean: 0.5350626137089588\n",
      "Kappa SD: 0.05161814934915149\n"
     ]
    }
   ],
   "source": [
    "# First version, we will loop manually, illustrate how data indices are selected\n",
    "xval = model_selection.KFold(10, shuffle=True) \n",
    "all_kappas = []  \n",
    "all_predictions = []  \n",
    "\n",
    "for train_i, test_i in xval.split(combined_df):\n",
    "    # For each fold, the fold is split into training indices (train_i) and test indices (test_i).\n",
    "    print('New cross-validation fold')\n",
    "    print(train_i[:10])\n",
    "    print(test_i[:10])\n",
    "    print(len(train_i), len(test_i))\n",
    "\n",
    "    # Find data rows from combined_df dataframe for each fold based on the indices train_i and test_i.\n",
    "    train_df = combined_df.iloc[train_i]\n",
    "    test_df = combined_df.iloc[test_i]\n",
    "\n",
    "    # Features and labels\n",
    "    train_X = train_df[features]\n",
    "    test_X = test_df[features]\n",
    "    train_y = train_df['class']\n",
    "    test_y = test_df['class']\n",
    "\n",
    "    # Build DT on fold train set, eval on fold test set\n",
    "    model = tree.DecisionTreeClassifier(min_samples_leaf=10)\n",
    "    model.fit(train_X, train_y)\n",
    "    predictions = model.predict(test_X)\n",
    "    kappa = metrics.cohen_kappa_score(test_y, predictions)\n",
    "    print('Kappa:', kappa)\n",
    "    all_predictions.extend(predictions)  # Save for averaging\n",
    "    all_kappas.append(kappa)             # Save for averaging\n",
    "\n",
    "print('Kappa mean:', np.mean(all_kappas))  # Average\n",
    "print('Kappa SD:', np.std(all_kappas))     # Standard deviation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cross_validate\n",
    "\n",
    "Useful and simpler for some future homework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00803757, 0.00399899, 0.00399685, 0.00400782, 0.00403404,\n",
       "        0.0039916 , 0.00399518, 0.00401521, 0.00700378, 0.00500011]),\n",
       " 'score_time': array([0.0026114 , 0.00394821, 0.00199962, 0.00199056, 0.00199986,\n",
       "        0.00200152, 0.0020113 , 0.00260019, 0.00565767, 0.0030117 ]),\n",
       " 'test_score': array([0.54203043, 0.51329243, 0.59693752, 0.49329359, 0.69098712,\n",
       "        0.58631335, 0.59743992, 0.53520041, 0.57583751, 0.44819341]),\n",
       " 'train_score': array([0.69790369, 0.69788818, 0.6797876 , 0.69896104, 0.67231555,\n",
       "        0.69124188, 0.69848085, 0.70931052, 0.68573266, 0.70989726])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeating example using cross_validate; makes life easier, and helps prevent mistakes!\n",
    "from sklearn import neighbors\n",
    "\n",
    "model = tree.DecisionTreeClassifier(min_samples_leaf=10)\n",
    "# model = neighbors.KNeighborsClassifier(3)\n",
    "X = combined_df[features]\n",
    "y = combined_df['class']\n",
    "xval = model_selection.KFold(10, shuffle=True)\n",
    "\n",
    "# Create custom scorer \n",
    "# A scorer is a wrapper around an arbitrary metric or loss function that is called with signature scorer(estimator, X, y_true, **kwargs).\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html\n",
    "scorer = metrics.make_scorer(metrics.cohen_kappa_score)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n",
    "results = model_selection.cross_validate(model, X, y, cv=xval, scoring=scorer, return_train_score=True)\n",
    "results\n",
    "\n",
    "# {\n",
    "#   'fit_time': array([...]),      # Time taken to fit the model for each fold\n",
    "#   'score_time': array([...]),    # Time taken to score the model for each fold\n",
    "#   'test_score': array([...]),    # Cohen's Kappa scores on the test set for each fold\n",
    "#   'train_score': array([...])    # Cohen's Kappa scores on the training set for each fold\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54203043 0.51329243 0.59693752 0.49329359 0.69098712 0.58631335\n",
      " 0.59743992 0.53520041 0.57583751 0.44819341]\n",
      "[0.69790369 0.69788818 0.6797876  0.69896104 0.67231555 0.69124188\n",
      " 0.69848085 0.70931052 0.68573266 0.70989726]\n",
      "Test kappa mean: 0.5579525697481794\n",
      "Test kappa SD: 0.06394922489283968\n",
      "Train kappa mean: 0.6941519228870457\n",
      "Train kappa SD: 0.011446024811243738\n"
     ]
    }
   ],
   "source": [
    "print(results['test_score'])\n",
    "print(results['train_score'])\n",
    "\n",
    "print('Test kappa mean:', results['test_score'].mean())\n",
    "print('Test kappa SD:', results['test_score'].std())\n",
    "print('Train kappa mean:', results['train_score'].mean())\n",
    "print('Train kappa SD:', results['train_score'].std())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try `min_samples_leaf` down to 1 to observe overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008038</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.542030</td>\n",
       "      <td>0.697904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.513292</td>\n",
       "      <td>0.697888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.596938</td>\n",
       "      <td>0.679788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.493294</td>\n",
       "      <td>0.698961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.690987</td>\n",
       "      <td>0.672316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.586313</td>\n",
       "      <td>0.691242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.597440</td>\n",
       "      <td>0.698481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.535200</td>\n",
       "      <td>0.709311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007004</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.685733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.448193</td>\n",
       "      <td>0.709897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.008038    0.002611    0.542030     0.697904\n",
       "1  0.003999    0.003948    0.513292     0.697888\n",
       "2  0.003997    0.002000    0.596938     0.679788\n",
       "3  0.004008    0.001991    0.493294     0.698961\n",
       "4  0.004034    0.002000    0.690987     0.672316\n",
       "5  0.003992    0.002002    0.586313     0.691242\n",
       "6  0.003995    0.002011    0.597440     0.698481\n",
       "7  0.004015    0.002600    0.535200     0.709311\n",
       "8  0.007004    0.005658    0.575838     0.685733\n",
       "9  0.005000    0.003012    0.448193     0.709897"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (very optional) We can also make a Dataframe for results, e.g., do some post-analysis or save them in a file.\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting scores of one specific class\n",
    "We need to revert to manual loops if we need k-fold scores for one specific class :(\n",
    "\n",
    "Very useful though, for example when data are imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.7979197622585439\n",
      "Kappa: 0.6406869220607663\n",
      "Kappa: 0.31658291457286425\n",
      "Kappa: 0.5603448275862069\n",
      "Kappa: 0.6406869220607663\n",
      "Kappa: 0.231357552581262\n",
      "Kappa: 0.39639639639639634\n",
      "Kappa: 0.4931921331316187\n",
      "Kappa: 0.5491251682368775\n",
      "Kappa: 0.12812812812812802\n",
      "Kappa mean: 0.47544207270134303\n",
      "Kappa SD: 0.19576644295252843\n"
     ]
    }
   ],
   "source": [
    "xval = model_selection.KFold(10, shuffle=True)\n",
    "specific_kappas = []\n",
    "for train_i, test_i in xval.split(combined_df):\n",
    "    train_df = combined_df.iloc[train_i]\n",
    "    test_df = combined_df.iloc[test_i]\n",
    "    model = tree.DecisionTreeClassifier(min_samples_leaf=10)\n",
    "    model.fit(train_df[features], train_df['class'])\n",
    "    predictions = model.predict(test_df[features])\n",
    "    specific_predictions = predictions == 'building '\n",
    "    specific_y = test_df['class'] == 'building '\n",
    "    kappa = metrics.cohen_kappa_score(specific_y, specific_predictions)\n",
    "    print('Kappa:', kappa)\n",
    "    specific_kappas.append(kappa)\n",
    "\n",
    "print('Kappa mean:', np.mean(specific_kappas))\n",
    "print('Kappa SD:', np.std(specific_kappas))\n",
    "\n",
    "# Then change from building to \"pool \", the least common class, and observe kappa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d71d710373b91b5ba8b9add0247bbe6b7aa2fbda93bfeeeeeeb5cf5637b6b1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
