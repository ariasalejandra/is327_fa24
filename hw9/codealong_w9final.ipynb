{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics, fairness, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quiz1</th>\n",
       "      <th>quiz2</th>\n",
       "      <th>quiz3</th>\n",
       "      <th>quiz4</th>\n",
       "      <th>quiz5</th>\n",
       "      <th>quiz6</th>\n",
       "      <th>quiz7</th>\n",
       "      <th>quiz8</th>\n",
       "      <th>quiz9</th>\n",
       "      <th>quiz10</th>\n",
       "      <th>passed_final</th>\n",
       "      <th>frpl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.006812</td>\n",
       "      <td>84.410831</td>\n",
       "      <td>45.160440</td>\n",
       "      <td>70.889405</td>\n",
       "      <td>54.310410</td>\n",
       "      <td>63.434932</td>\n",
       "      <td>60.601137</td>\n",
       "      <td>45.117798</td>\n",
       "      <td>95.797734</td>\n",
       "      <td>93.570121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.730824</td>\n",
       "      <td>64.917864</td>\n",
       "      <td>14.581339</td>\n",
       "      <td>57.132101</td>\n",
       "      <td>53.962630</td>\n",
       "      <td>21.741871</td>\n",
       "      <td>84.847961</td>\n",
       "      <td>64.160859</td>\n",
       "      <td>86.419329</td>\n",
       "      <td>74.628074</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.885607</td>\n",
       "      <td>75.564349</td>\n",
       "      <td>62.434004</td>\n",
       "      <td>56.603925</td>\n",
       "      <td>63.137982</td>\n",
       "      <td>56.910331</td>\n",
       "      <td>89.608642</td>\n",
       "      <td>71.231343</td>\n",
       "      <td>88.324471</td>\n",
       "      <td>92.695640</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.414426</td>\n",
       "      <td>91.062155</td>\n",
       "      <td>46.457298</td>\n",
       "      <td>54.037249</td>\n",
       "      <td>56.861984</td>\n",
       "      <td>41.587869</td>\n",
       "      <td>77.980740</td>\n",
       "      <td>52.233073</td>\n",
       "      <td>84.232572</td>\n",
       "      <td>90.006458</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.767233</td>\n",
       "      <td>86.944637</td>\n",
       "      <td>31.068615</td>\n",
       "      <td>60.965026</td>\n",
       "      <td>6.832854</td>\n",
       "      <td>46.313645</td>\n",
       "      <td>76.056575</td>\n",
       "      <td>40.544819</td>\n",
       "      <td>89.014045</td>\n",
       "      <td>88.661454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>38.858685</td>\n",
       "      <td>85.199900</td>\n",
       "      <td>90.734316</td>\n",
       "      <td>37.451876</td>\n",
       "      <td>24.785567</td>\n",
       "      <td>55.901637</td>\n",
       "      <td>80.822082</td>\n",
       "      <td>70.993635</td>\n",
       "      <td>78.794029</td>\n",
       "      <td>77.143443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>31.218415</td>\n",
       "      <td>79.372650</td>\n",
       "      <td>49.181140</td>\n",
       "      <td>52.887378</td>\n",
       "      <td>47.580652</td>\n",
       "      <td>58.234047</td>\n",
       "      <td>86.362499</td>\n",
       "      <td>69.481944</td>\n",
       "      <td>84.092804</td>\n",
       "      <td>88.170802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>41.546260</td>\n",
       "      <td>91.159578</td>\n",
       "      <td>53.578852</td>\n",
       "      <td>57.828196</td>\n",
       "      <td>11.955848</td>\n",
       "      <td>53.583460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.325711</td>\n",
       "      <td>75.683433</td>\n",
       "      <td>80.104594</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>52.719078</td>\n",
       "      <td>13.704376</td>\n",
       "      <td>51.123489</td>\n",
       "      <td>41.120479</td>\n",
       "      <td>98.853494</td>\n",
       "      <td>68.902541</td>\n",
       "      <td>82.814987</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>61.779517</td>\n",
       "      <td>83.805873</td>\n",
       "      <td>68.703272</td>\n",
       "      <td>30.256937</td>\n",
       "      <td>39.696539</td>\n",
       "      <td>52.461496</td>\n",
       "      <td>88.507602</td>\n",
       "      <td>48.203584</td>\n",
       "      <td>90.153823</td>\n",
       "      <td>80.056676</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          quiz1       quiz2      quiz3      quiz4      quiz5      quiz6  \\\n",
       "0     65.006812   84.410831  45.160440  70.889405  54.310410  63.434932   \n",
       "1     30.730824   64.917864  14.581339  57.132101  53.962630  21.741871   \n",
       "2     35.885607   75.564349  62.434004  56.603925  63.137982  56.910331   \n",
       "3     59.414426   91.062155  46.457298  54.037249  56.861984  41.587869   \n",
       "4     54.767233   86.944637  31.068615  60.965026   6.832854  46.313645   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "395   38.858685   85.199900  90.734316  37.451876  24.785567  55.901637   \n",
       "396   31.218415   79.372650  49.181140  52.887378  47.580652  58.234047   \n",
       "397   41.546260   91.159578  53.578852  57.828196  11.955848  53.583460   \n",
       "398  100.000000  100.000000  52.719078  13.704376  51.123489  41.120479   \n",
       "399   61.779517   83.805873  68.703272  30.256937  39.696539  52.461496   \n",
       "\n",
       "         quiz7      quiz8      quiz9      quiz10  passed_final  frpl  \n",
       "0    60.601137  45.117798  95.797734   93.570121             1     0  \n",
       "1    84.847961  64.160859  86.419329   74.628074             0     1  \n",
       "2    89.608642  71.231343  88.324471   92.695640             0     1  \n",
       "3    77.980740  52.233073  84.232572   90.006458             1     0  \n",
       "4    76.056575  40.544819  89.014045   88.661454             0     0  \n",
       "..         ...        ...        ...         ...           ...   ...  \n",
       "395  80.822082  70.993635  78.794029   77.143443             1     1  \n",
       "396  86.362499  69.481944  84.092804   88.170802             0     0  \n",
       "397   0.000000  66.325711  75.683433   80.104594             1     1  \n",
       "398  98.853494  68.902541  82.814987  100.000000             1     0  \n",
       "399  88.507602  48.203584  90.153823   80.056676             0     0  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Quiz grades, final pass grade, free/reduced-price lunch eligibility\n",
    "df = pd.read_csv('course_passing_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "In linear regression, the outcome is a continuous value, directly modeled as a linear combination of features (e.g., `y = b0 + b1*x1 + b2*x2 + ...`). To handle classification problems, logistic regression modifies linear regression using a logistic (sigmoid) function to constrain the output to the 0-1 range, representing a probability (e.g., `p = 1 / (1 + exp(-(b0 + b1*x1 + b2*x2 + ...)))`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a linear regression model\n",
    "from sklearn import linear_model\n",
    "\n",
    "features = []\n",
    "for column in df.columns:\n",
    "    if column.startswith('quiz'):\n",
    "        features.append(column)\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(df[features], df.passed_final)\n",
    "pred = model.predict(df[features])\n",
    "pd.Series(pred).describe()\n",
    "# Note how these predictions are not good\n",
    "# They don't make sense for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead we will transform the predictions to be squashed in 0/1\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(df[features], df.passed_final)\n",
    "pred = model.predict(df[features])\n",
    "pd.Series(pred).value_counts()\n",
    "# Might give a scaling warning since we have not used standardization!\n",
    "# scikit-learn Pipelines would help streamline ML workflows by allowing scaling and other kinds of transformations \n",
    "# to be bundled together with a model. More on this later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "train_df = df.iloc[:300]\n",
    "test_df = df.iloc[300:]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[features])\n",
    "train_X = scaler.transform(train_df[features])\n",
    "test_X = scaler.transform(test_df[features])\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(train_X, train_df.passed_final)\n",
    "pred = model.predict(test_X)\n",
    "pd.Series(pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline, metrics\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    ('scaling', preprocessing.StandardScaler()),\n",
    "    ('model', linear_model.LogisticRegression())\n",
    "])\n",
    "pipe.fit(train_df[features], train_df.passed_final)\n",
    "preds = pipe.predict(test_df[features])\n",
    "\n",
    "print('Test kappa:', metrics.cohen_kappa_score(test_df.passed_final, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also use pipelines in cross-validation, same as a model\n",
    "from sklearn import model_selection\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    ('scaling', preprocessing.StandardScaler()),\n",
    "    ('model', linear_model.LogisticRegression())\n",
    "])\n",
    "xval = model_selection.KFold(10, shuffle=True)\n",
    "scorer = metrics.make_scorer(metrics.cohen_kappa_score)\n",
    "result = model_selection.cross_validate(\n",
    "    pipe, df[features], df.passed_final,\n",
    "    return_train_score=True, cv=xval,\n",
    "    scoring=scorer)\n",
    "\n",
    "print('Kappa:', result['test_score'].mean())\n",
    "print('Kappa SD:', result['test_score'].std())\n",
    "print('Train kappa mean:', result['train_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness\n",
    "Let's take a look at the predictions for different frpl groups (free/reduced-price lunch eligibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(train_df[features], train_df.passed_final)\n",
    "preds = pipe.predict(test_df[features])\n",
    "\n",
    "output_df = test_df.copy()\n",
    "output_df['prediction'] = preds\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frpl_rows = output_df[output_df.frpl == 1]\n",
    "non_frpl_rows = output_df[output_df.frpl == 0]\n",
    "print('FRPL kappa:', metrics.cohen_kappa_score(frpl_rows.passed_final, frpl_rows.prediction))\n",
    "print('Non-FRPL kappa:', metrics.cohen_kappa_score(non_frpl_rows.passed_final, non_frpl_rows.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that the model is more accurate for non-frpl students?\n",
    "Let's take a closer look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(output_df.passed_final, output_df.prediction)\n",
    "# NOTE: Scikit-learn sorts labels in the matrix, so for binary classification it goes:\n",
    "#   TN FP\n",
    "#   FN TP\n",
    "# Whereas the conventional order is:\n",
    "#   [True positive (TP),   False negative (FN)\n",
    "#    False positive (FP),  True negative (TN) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FRPL')\n",
    "print(metrics.confusion_matrix(frpl_rows.passed_final, frpl_rows.prediction))\n",
    "\n",
    "print('\\nNon-FRPL')\n",
    "print(metrics.confusion_matrix(non_frpl_rows.passed_final, non_frpl_rows.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://scikit-learn.org/stable/api/sklearn.metrics.html#classification-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kappa, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Scikit-learn sorts labels in the matrix, so for binary classification it goes:\n",
    "#   TN FP\n",
    "#   FN TP\n",
    "# Whereas the conventional order is:\n",
    "#   [True positive (TP),   False negative (FN)\n",
    "#    False positive (FP),  True negative (TN) ]\n",
    "\n",
    "# (57 + 11) / (57 + 3 + 29 + 11)  # prop. correct\n",
    "print(metrics.confusion_matrix(output_df.passed_final, output_df.prediction))\n",
    "\n",
    "# 11/(11+29)\n",
    "print(metrics.recall_score(output_df.passed_final, output_df.prediction))\n",
    "\n",
    "# 11/(11+3)\n",
    "print(metrics.precision_score(output_df.passed_final, output_df.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.roc_auc_score(output_df.passed_final, output_df.prediction))\n",
    "print(metrics.f1_score(output_df.passed_final, output_df.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score measures of the ability of the model to distinguish between the classes. \n",
    "An AUC of 0.5 suggests no discrimination (i.e., random chance), and an AUC of 1.0 indicates perfect discrimination. \n",
    "The model's AUC score of approximately 0.6125 means it is better than random guessing ... but far from perfect.\n",
    "\n",
    "F1 is the harmonic mean of precision and recall, and is particularly useful when there is an uneven class distribution / class imbalance.\n",
    "An F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. \n",
    "The F1 score of approximately 0.4074 indicates that the model is not very effective in terms of balancing precision and recall, typically suggesting either a low precision or a low recall or both. We have 0.275 recall and 0.786 precision so we know that our model has low recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding metrics to a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline.Pipeline([\n",
    "    ('scaling', preprocessing.StandardScaler()),\n",
    "    ('model', linear_model.LogisticRegression())\n",
    "])\n",
    "xval = model_selection.KFold(10, shuffle=True)\n",
    "scorer = {\n",
    "    'kappa': metrics.make_scorer(metrics.cohen_kappa_score),\n",
    "    'accuracy': metrics.make_scorer(metrics.accuracy_score),\n",
    "    'precision': metrics.make_scorer(metrics.precision_score),\n",
    "    'recall': metrics.make_scorer(metrics.recall_score)\n",
    "}\n",
    "result = model_selection.cross_validate(pipe, df[features], df.passed_final, return_train_score=True,\n",
    "    cv=xval, scoring=scorer)\n",
    "\n",
    "print('Test kappa:', result['test_kappa'].mean())\n",
    "print('Test accuracy:', result['test_accuracy'].mean())\n",
    "print('Test precision:', result['test_precision'].mean())\n",
    "print('Test recall:', result['test_recall'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Introducing GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "scorer = metrics.make_scorer(metrics.cohen_kappa_score)\n",
    "grid = {\n",
    "    'min_samples_split': [2, 4, 8, 16, 32, 64],\n",
    "     'max_features': [.1, .5, .75],\n",
    "}\n",
    "gridsearch = model_selection.GridSearchCV(model, grid, scoring=scorer)\n",
    "result = model_selection.cross_validate(\n",
    "    gridsearch, df[features], df.passed_final,\n",
    "    return_train_score=True, cv=xval,\n",
    "    scoring=scorer)\n",
    "\n",
    "# Sometimes gets unlucky w/low kappa\n",
    "print('Kappa:', result['test_score'].mean())\n",
    "print('Kappa SD:', result['test_score'].std())\n",
    "print('Train kappa:', result['train_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pipelines and hyperparameter tuning together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.cohen_kappa_score)\n",
    "model = neighbors.KNeighborsClassifier()\n",
    "grid = {\n",
    "    'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],\n",
    "}\n",
    "gridsearch = model_selection.GridSearchCV(model, grid, scoring=scorer)\n",
    "pipe = pipeline.Pipeline([\n",
    "    ('scaling', preprocessing.StandardScaler()),\n",
    "    ('model', gridsearch),\n",
    "])\n",
    "xval = model_selection.KFold(10, shuffle=True)\n",
    "result = model_selection.cross_validate(pipe, df[features], df.passed_final,\n",
    "    return_train_score=True, cv=xval, scoring=scorer)\n",
    "print('Kappa mean:', result['test_score'].mean())\n",
    "print('Kappa SD:', result['test_score'].std())\n",
    "print('Train kappa mean:', result['train_score'].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression w/random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "four_features = ['quiz1', 'quiz2', 'quiz3', 'quiz4']\n",
    "scorer = metrics.make_scorer(metrics.r2_score)  \n",
    "model = ensemble.RandomForestRegressor()\n",
    "grid = {\n",
    "    'min_samples_leaf': [1, 4, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "gridsearch = model_selection.GridSearchCV(model, grid, scoring=scorer)\n",
    "result = model_selection.cross_validate(gridsearch, df[four_features], df.quiz10,\n",
    "    return_train_score=True, cv=xval, scoring=scorer)  # scoring='r2'\n",
    "print('R^2 mean:', result['test_score'].mean())\n",
    "print('R^2 SD:', result['test_score'].std())\n",
    "print('Train R^2 mean:', result['train_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also, checkout ROC curves and micro/macro-averaging \n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
